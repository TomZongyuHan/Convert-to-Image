Index: test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Test for the pipeline\n# Import library and methods\nfrom methods import dataCleanAndNormalize\nfrom methods import dimensionalityReduce\nfrom methods import imageConvert\nfrom methods import imageEnhance\nfrom methods import CNNTrain\nfrom methods import calculateAccuracy\n\n\n# test methods included in the pipeline\n# Input:\n#   filename: string value, the name of csv file (include .csv)\n#       dataset file should be put in ./originalDatasets\n#   isRowCount: boolean value,\n#       if dataset is row count, use True\n#       if dataset is not row count, use False\n# Output:\n#   result files will be showed in commond line\ndef test(filename, isRowCount):\n    # Set file path\n    filepath = 'originalDatasets/' + filename\n\n    # Set all methods need to be test\n    normNames = ['linnorm']\n    drNames = ['pca']\n    icNames = ['deepinsight']\n    CNNNames = ['vgg16']\n\n    # Run all methods and output results\n    finishNum = 0  # use a number to calculate how many method have finished\n    allNum = len(normNames) * len(drNames) * len(icNames) * len(CNNNames)  # calculate how many methods exist\n    for normName in normNames:\n        # Data clean and normalize\n        normalizedDataset = dataCleanAndNormalize.dataCleanAndNormalize(filepath, isRowCount, normName)\n        for drName in drNames:\n            # Dimensionality reduce\n            # drDataset = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, False)\n            drResult = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, True)\n            for icName in icNames:\n                imageDataset = imageConvert.imageConvert(drResult, icName) # Image convert\n                # enhancedDataset = imageEnhance(imageDataset) # Image enhance\n                # for CNNName in CNNNames:\n                #     # result = CNNTrain(enhancedDataset, CNNName) # CNN train\n                #     # calculateAccuracy(result) # Calculate accuracy\n                #     finishNum += 1\n                #     print('----- ' +\n                #           normName + '-' +\n                #           drName + '-' +\n                #           icName + '-' +\n                #           CNNName + ' finish ' +\n                #           str(finishNum) + '/' + str(allNum))\n\n    # Test return\n    return imageDataset\n\n\n# Run test\nfilename = 'test-RowCount.csv'\ntestRes = test(filename, True)\nprint(\"shape of imageDataset: \" + str(testRes.shape))\nprint(testRes)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- test.py	(revision 3bbcad3f6592b0ed7199793f1b8dc86e9d0d45d9)
+++ test.py	(date 1631184920926)
@@ -33,12 +33,12 @@
     for normName in normNames:
         # Data clean and normalize
         normalizedDataset = dataCleanAndNormalize.dataCleanAndNormalize(filepath, isRowCount, normName)
-        for drName in drNames:
-            # Dimensionality reduce
-            # drDataset = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, False)
-            drResult = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, True)
-            for icName in icNames:
-                imageDataset = imageConvert.imageConvert(drResult, icName) # Image convert
+        # for drName in drNames:
+        #     # Dimensionality reduce
+        #     # drDataset = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, False)
+        #     drResult = dimensionalityReduce.dimensionalityReduce(normalizedDataset, drName, True)
+        #     for icName in icNames:
+        #         imageDataset = imageConvert.imageConvert(drResult, icName) # Image convert
                 # enhancedDataset = imageEnhance(imageDataset) # Image enhance
                 # for CNNName in CNNNames:
                 #     # result = CNNTrain(enhancedDataset, CNNName) # CNN train
@@ -52,7 +52,7 @@
                 #           str(finishNum) + '/' + str(allNum))
 
     # Test return
-    return imageDataset
+    return normalizedDataset
 
 
 # Run test
Index: methods/dataCleanAndNormalize.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Import library and methods\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects as robjects\nfrom rpy2.robjects import pandas2ri\nfrom rpy2.robjects.conversion import localconverter\nimport numpy as np\nimport pandas as pd\n\n\n# Call R file to clean and normalize dataset\n# Input:\n#   filepath: string value, the path of csv file\n#   isRowCount: boolean value,\n#       if dataset is row count, use True\n#       if dataset is not row count, use False\n#   normName: string value, the name of normalization method\n# Output:\n#   normalizedDataset: the variable store normalized dataset\ndef dataCleanAndNormalize(filepath, isRowCount, normName):\n    # Transform variable 'isRowCount' to String\n    if(isRowCount):\n        isRowCount = 'TRUE'\n    else:\n        isRowCount = 'FALSE'\n\n    # Prepare R variable\n    filepath = '\\\"' + filepath + '\\\"'\n    isRowCount = '\\\"' + isRowCount + '\\\"'\n    normName = '\\\"' + normName + '\\\"'\n\n    # Transform python String to R String\n    robjects.r('''\n        path  <- gsub(\"to\", \"\",''' + filepath + ''')\n        isRowCount <- gsub(\"to\", \"\",''' + isRowCount + ''')\n        normname <- gsub(\"to\", \"\",''' + normName + ''')\n    ''')\n\n    # Import R's packages\n    importr('Linnorm')  # for linnorm\n    importr('scone')  # for scone/TTM/scran\n    importr('edgeR')  # for cpm\n    importr('Seurat')  # for seurat\n\n    robjects.r(\"\"\"\n            # This function used to read, clean and normalize data\n            # Input:\n            #   path: data csv file path\n            #   normName: normalization method name, should be linnorm/scone/ttm/scran/cpm/seurat\n            # Rerutn:\n            #   processed data: rows - genes, columns - cells\n            processDataset <- function(path, isRowCount, normname) {\n            # Read the CSV file and convert it to matrix format\n            rowdata <- read.table(path, sep = \",\", header = FALSE)\n            rowdata <- as.matrix(rowdata)\n        \n            # Determine if the raw data need to transpose\n            if(isRowCount==\"FALSE\"){\n                # Transpose the matrix\n                rowdata <- t(rowdata)\n            }\n        \n            # Delete the rows containing remove names\n            removeNames <- c(\"alpha.contaminated\", \"beta.contaminated\", \"delta.contaminated\", \"Excluded\", \"gamma.contaminated\", \"miss\", \"NA\",\"not applicable\", \"unclassified\", \"unknown\", \"Unknown\", \"zothers\")\n            for (name in removeNames) {\n                rowdata <- rowdata[!grepl(name, rowdata[, 1]), ]\n            }\n        \n            # Save colume name and row name\n            cn <- rowdata[, 1]\n            rn <- rowdata[1, ]\n            rn_c <- \"\"\n            for (name in rn[-1]) {\n                rn_c <- c(rn_c, name)\n            }\n        \n            # Discard first row and first column (row name, column name)\n            rowdata <- rowdata[-1, -1]\n        \n            # Convert character data in the matrix to double data using the mode() method\n            mode(rowdata) <- \"double\"\n        \n            # Check whether NA is still present in the matrix\n            any(is.na(rowdata))\n        \n            # Transpose the matrix, ready for use in the normalization method\n            rowdata <- t(rowdata)\n        \n            # Run different normalize methods accroding to input param\n            if (normname == \"linnorm\") {\n                rowdata <- Linnorm(rowdata, minNonZeroPortion = 0.2)\n            } else if (normname == \"scran\") {\n                rowdata <- SCRAN_FN(rowdata)\n            } else if (normname == \"tmm\") {\n                rowdata <- TMM_FN(rowdata)\n            } else if (normname == \"scone\") {\n                rowdata <- DESEQ_FN(rowdata)\n            } else if (normname == \"cpm\") {\n                rowdata <- cpm(rowdata, log=FALSE)\n            } else if (normname == \"seurat\") {\n                rowdata <- as.matrix(NormalizeData(rowdata))\n            } \n        \n            # Add the rowname and colname of dataset\n            # rownames(rowdata) <- rn[-1]\n            colnames(rowdata) <- cn[-1]\n\n            return(rowdata)\n        }\n    \"\"\")\n\n    robjects.r(\"\"\"\n        res = processDataset(path, isRowCount, normname)\n    \"\"\")\n\n    dataframe = robjects.reval(\"res\")\n    # normalized_dataset = np.array(dataframe)\n    with localconverter(robjects.default_converter + pandas2ri.converter):\n        normalized_dataset = pd.DataFrame(data = robjects.conversion.rpy2py(dataframe))\n        normalized_dataset.columns = normalized_dataset.iloc[0]\n        normalized_dataset.drop(normalized_dataset.index[0])\n\n    # Return processed dataset\n    return normalized_dataset\n\n\n# Test\n# filepath = '../originalDatasets/' + 'yan-RowCount.csv'\n# normalized_dataset = dataCleanAndNormalize(filepath, True, \"linnorm\")\n# print(normalized_dataset)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- methods/dataCleanAndNormalize.py	(revision 3bbcad3f6592b0ed7199793f1b8dc86e9d0d45d9)
+++ methods/dataCleanAndNormalize.py	(date 1631185852960)
@@ -103,7 +103,14 @@
             # Add the rowname and colname of dataset
             # rownames(rowdata) <- rn[-1]
             colnames(rowdata) <- cn[-1]
-
+            
+            # convert colnames to numeric data
+            
+            
+            for(){
+            
+            }
+            
             return(rowdata)
         }
     """)
